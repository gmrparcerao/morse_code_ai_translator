{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import initializers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renan data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "renan = pd.DataFrame()\n",
    "\n",
    "# for each file in directory, create a new dataframe\n",
    "folder = \"../letters_csv_writer/letters/Renan\"\n",
    "for directory, subfolder, files in os.walk(folder):     \n",
    "     for file in files:\n",
    "          targetLetter = file.replace(\".csv\",\"\")\n",
    "          # Create a dataframe without header and drop last column\n",
    "          df = pd.DataFrame()\n",
    "          df = pd.read_csv(os.path.join(os.path.realpath(directory), file), header=None, sep=\";\")\n",
    "          df = df.drop(180, axis=1)\n",
    "          df[\"Target letter\"] = targetLetter\n",
    "          df[\"Target person\"] = \"Renan\"\n",
    "\n",
    "          renan = pd.concat([renan,df])\n",
    "          \n",
    "renan = renan.reset_index(drop=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guilherme dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "guilherme = pd.DataFrame()\n",
    "\n",
    "# for each file in directory, create a new dataframe\n",
    "folder = \"../letters_csv_writer/letters/Guilherme\"\n",
    "for directory, subfolder, files in os.walk(folder):     \n",
    "     for file in files:\n",
    "          targetLetter = file.replace(\".csv\",\"\")\n",
    "          # Create a dataframe without header and drop last column\n",
    "          df = pd.DataFrame()\n",
    "          df = pd.read_csv(os.path.join(os.path.realpath(directory), file), header=None, sep=\";\")\n",
    "          df = df.drop(180, axis=1)\n",
    "          df[\"Target letter\"] = targetLetter\n",
    "          df[\"Target person\"] = \"Guilherme\"\n",
    "\n",
    "          guilherme = pd.concat([guilherme,df])\n",
    "          \n",
    "guilherme = guilherme.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe Claudinei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "claudinei = pd.DataFrame()\n",
    "\n",
    "# for each file in directory, create a new dataframe\n",
    "folder = \"../letters_csv_writer/letters/Claudinei\"\n",
    "for directory, subfolder, files in os.walk(folder):     \n",
    "     for file in files:\n",
    "          targetLetter = file.replace(\".csv\",\"\")\n",
    "          # Create a dataframe without header and drop last column\n",
    "          df = pd.DataFrame()\n",
    "          df = pd.read_csv(os.path.join(os.path.realpath(directory), file), header=None, sep=\";\")\n",
    "          df = df.drop(180, axis=1)\n",
    "          df[\"Target letter\"] = targetLetter\n",
    "          df[\"Target person\"] = \"Claudinei\"\n",
    "\n",
    "          claudinei = pd.concat([claudinei,df])\n",
    "          \n",
    "claudinei = claudinei.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agroup dataframe's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>Target letter</th>\n",
       "      <th>Target person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>Renan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>Renan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>Renan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>Renan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>Renan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>Claudinei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>Claudinei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>Claudinei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>Claudinei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>Claudinei</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3642 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  172  173  174  175  176  177  178  \\\n",
       "0     0  1  1  1  1  1  1  1  1  0  ...    0    0    0    0    0    0    0   \n",
       "1     0  1  1  1  1  1  1  1  1  0  ...    0    0    0    0    0    0    0   \n",
       "2     0  1  1  1  1  1  1  1  1  0  ...    0    0    0    0    0    0    0   \n",
       "3     0  1  1  1  1  1  1  1  1  1  ...    0    0    0    0    0    0    0   \n",
       "4     0  1  1  1  1  1  1  1  1  1  ...    0    0    0    0    0    0    0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3637  0  1  1  1  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3638  0  1  1  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3639  0  1  1  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3640  0  1  1  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3641  0  1  1  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "      179  Target letter  Target person  \n",
       "0       0              A          Renan  \n",
       "1       0              A          Renan  \n",
       "2       0              A          Renan  \n",
       "3       0              A          Renan  \n",
       "4       0              A          Renan  \n",
       "...   ...            ...            ...  \n",
       "3637    0              U      Claudinei  \n",
       "3638    0              U      Claudinei  \n",
       "3639    0              U      Claudinei  \n",
       "3640    0              U      Claudinei  \n",
       "3641    0              U      Claudinei  \n",
       "\n",
       "[3642 rows x 182 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupDataframe = pd.concat([renan,guilherme, claudinei])\n",
    "groupDataframe = groupDataframe.reset_index(drop=True)\n",
    "groupDataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### separate input \"X\" and output \"Y\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3642 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  170  171  172  \\\n",
       "0       0    1    1    1    1    1    1    1    1    0  ...    0    0    0   \n",
       "1       0    1    1    1    1    1    1    1    1    0  ...    0    0    0   \n",
       "2       0    1    1    1    1    1    1    1    1    0  ...    0    0    0   \n",
       "3       0    1    1    1    1    1    1    1    1    1  ...    0    0    0   \n",
       "4       0    1    1    1    1    1    1    1    1    1  ...    0    0    0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3637    0    1    1    1    1    0    0    0    0    0  ...    0    0    0   \n",
       "3638    0    1    1    1    0    0    0    0    0    0  ...    0    0    0   \n",
       "3639    0    1    1    1    0    0    0    0    0    0  ...    0    0    0   \n",
       "3640    0    1    1    1    0    0    0    0    0    0  ...    0    0    0   \n",
       "3641    0    1    1    1    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "      173  174  175  176  177  178  179  \n",
       "0       0    0    0    0    0    0    0  \n",
       "1       0    0    0    0    0    0    0  \n",
       "2       0    0    0    0    0    0    0  \n",
       "3       0    0    0    0    0    0    0  \n",
       "4       0    0    0    0    0    0    0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "3637    0    0    0    0    0    0    0  \n",
       "3638    0    0    0    0    0    0    0  \n",
       "3639    0    0    0    0    0    0    0  \n",
       "3640    0    0    0    0    0    0    0  \n",
       "3641    0    0    0    0    0    0    0  \n",
       "\n",
       "[3642 rows x 180 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = groupDataframe.iloc[:,0:180]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       A\n",
       "1       A\n",
       "2       A\n",
       "3       A\n",
       "4       A\n",
       "       ..\n",
       "3637    U\n",
       "3638    U\n",
       "3639    U\n",
       "3640    U\n",
       "3641    U\n",
       "Name: Target letter, Length: 3642, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = groupDataframe.iloc[:,180]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv(\"groupletter.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network model in keras TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 180) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 180), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 180).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 180) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 180), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 180).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 180) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 180), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 180).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 180) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 180), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 180).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/137 [==========================>...] - ETA: 0s - loss: 1.5514 - mae: 1.0040WARNING:tensorflow:Model was constructed with shape (None, None, 180) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 180), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 180).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 180) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 180), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 180).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 2s 5ms/step - loss: 1.4629 - mae: 0.9677 - val_loss: 3.1734 - val_mae: 1.4243\n",
      "Epoch 2/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.4180 - mae: 0.5063 - val_loss: 2.6906 - val_mae: 1.2652\n",
      "Epoch 3/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.2573 - mae: 0.3754 - val_loss: 2.2001 - val_mae: 1.1597\n",
      "Epoch 4/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.1747 - mae: 0.2929 - val_loss: 1.9530 - val_mae: 1.0891\n",
      "Epoch 5/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.1329 - mae: 0.2456 - val_loss: 1.8509 - val_mae: 1.0604\n",
      "Epoch 6/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.1045 - mae: 0.2187 - val_loss: 1.5850 - val_mae: 0.9646\n",
      "Epoch 7/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0892 - mae: 0.1976 - val_loss: 1.7014 - val_mae: 1.0033\n",
      "Epoch 8/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0770 - mae: 0.1811 - val_loss: 1.7276 - val_mae: 1.0014\n",
      "Epoch 9/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0709 - mae: 0.1728 - val_loss: 1.5791 - val_mae: 0.9410\n",
      "Epoch 10/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0629 - mae: 0.1614 - val_loss: 1.3239 - val_mae: 0.8552\n",
      "Epoch 11/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0575 - mae: 0.1541 - val_loss: 1.5175 - val_mae: 0.9214\n",
      "Epoch 12/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0537 - mae: 0.1493 - val_loss: 1.6224 - val_mae: 0.9544\n",
      "Epoch 13/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 0.1398 - val_loss: 1.5292 - val_mae: 0.9129\n",
      "Epoch 14/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.1359 - val_loss: 1.3450 - val_mae: 0.8485\n",
      "Epoch 15/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1315 - val_loss: 1.4534 - val_mae: 0.8804\n",
      "Epoch 16/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1266 - val_loss: 1.5934 - val_mae: 0.9214\n",
      "Epoch 17/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0383 - mae: 0.1219 - val_loss: 1.4287 - val_mae: 0.8707\n",
      "Epoch 18/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1193 - val_loss: 1.5021 - val_mae: 0.8782\n",
      "Epoch 19/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1162 - val_loss: 1.4592 - val_mae: 0.8763\n",
      "Epoch 20/200\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0320 - mae: 0.1109 - val_loss: 1.3361 - val_mae: 0.8262\n",
      "Epoch 21/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1087 - val_loss: 1.2221 - val_mae: 0.7800\n",
      "Epoch 22/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1054 - val_loss: 1.2817 - val_mae: 0.8050\n",
      "Epoch 23/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1049 - val_loss: 1.4119 - val_mae: 0.8446\n",
      "Epoch 24/200\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0261 - mae: 0.1014 - val_loss: 1.2953 - val_mae: 0.8048\n",
      "Epoch 25/200\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0255 - mae: 0.0997 - val_loss: 1.3873 - val_mae: 0.8388\n",
      "Epoch 26/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.0977 - val_loss: 1.2684 - val_mae: 0.7948\n",
      "Epoch 27/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.0970 - val_loss: 1.3168 - val_mae: 0.8081\n",
      "Epoch 28/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0219 - mae: 0.0922 - val_loss: 1.3753 - val_mae: 0.8292\n",
      "Epoch 29/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.0889 - val_loss: 1.5619 - val_mae: 0.9041\n",
      "Epoch 30/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0202 - mae: 0.0878 - val_loss: 1.2788 - val_mae: 0.7889\n",
      "Epoch 31/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.0881 - val_loss: 1.0814 - val_mae: 0.7196\n",
      "Epoch 32/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0859 - val_loss: 1.1907 - val_mae: 0.7603\n",
      "Epoch 33/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0862 - val_loss: 1.3306 - val_mae: 0.8145\n",
      "Epoch 34/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0838 - val_loss: 1.3217 - val_mae: 0.8079\n",
      "Epoch 35/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0815 - val_loss: 1.1721 - val_mae: 0.7555\n",
      "Epoch 36/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0817 - val_loss: 1.1914 - val_mae: 0.7560\n",
      "Epoch 37/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0797 - val_loss: 1.2945 - val_mae: 0.7981\n",
      "Epoch 38/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0790 - val_loss: 1.2069 - val_mae: 0.7621\n",
      "Epoch 39/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0768 - val_loss: 1.3789 - val_mae: 0.8303\n",
      "Epoch 40/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0774 - val_loss: 1.1747 - val_mae: 0.7451\n",
      "Epoch 41/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0740 - val_loss: 1.2560 - val_mae: 0.7790\n",
      "Epoch 42/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0744 - val_loss: 1.2341 - val_mae: 0.7644\n",
      "Epoch 43/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0726 - val_loss: 1.2266 - val_mae: 0.7672\n",
      "Epoch 44/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0717 - val_loss: 1.2817 - val_mae: 0.7806\n",
      "Epoch 45/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0707 - val_loss: 1.2717 - val_mae: 0.7683\n",
      "Epoch 46/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0703 - val_loss: 1.4249 - val_mae: 0.8403\n",
      "Epoch 47/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0729 - val_loss: 1.2251 - val_mae: 0.7587\n",
      "Epoch 48/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0699 - val_loss: 1.2785 - val_mae: 0.7810\n",
      "Epoch 49/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0700 - val_loss: 1.1741 - val_mae: 0.7299\n",
      "Epoch 50/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0685 - val_loss: 1.0954 - val_mae: 0.7054\n",
      "Epoch 51/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0687 - val_loss: 1.1660 - val_mae: 0.7306\n",
      "Epoch 52/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0129 - mae: 0.0675 - val_loss: 1.2200 - val_mae: 0.7582\n",
      "Epoch 53/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0669 - val_loss: 1.1096 - val_mae: 0.7094\n",
      "Epoch 54/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0127 - mae: 0.0659 - val_loss: 1.1513 - val_mae: 0.7234\n",
      "Epoch 55/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0654 - val_loss: 1.0300 - val_mae: 0.6827\n",
      "Epoch 56/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0662 - val_loss: 1.1702 - val_mae: 0.7284\n",
      "Epoch 57/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0646 - val_loss: 1.0321 - val_mae: 0.6780\n",
      "Epoch 58/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0635 - val_loss: 1.0109 - val_mae: 0.6684\n",
      "Epoch 59/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0118 - mae: 0.0634 - val_loss: 1.2405 - val_mae: 0.7543\n",
      "Epoch 60/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0117 - mae: 0.0638 - val_loss: 1.1507 - val_mae: 0.7207\n",
      "Epoch 61/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0114 - mae: 0.0617 - val_loss: 1.1194 - val_mae: 0.7107\n",
      "Epoch 62/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0113 - mae: 0.0618 - val_loss: 1.1327 - val_mae: 0.7094\n",
      "Epoch 63/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0113 - mae: 0.0612 - val_loss: 1.0653 - val_mae: 0.6816\n",
      "Epoch 64/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0607 - val_loss: 1.0541 - val_mae: 0.6796\n",
      "Epoch 65/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0598 - val_loss: 1.0784 - val_mae: 0.6866\n",
      "Epoch 66/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0605 - val_loss: 1.0670 - val_mae: 0.6786\n",
      "Epoch 67/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0577 - val_loss: 1.1173 - val_mae: 0.7001\n",
      "Epoch 68/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0605 - val_loss: 1.1190 - val_mae: 0.6993\n",
      "Epoch 69/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0583 - val_loss: 1.2038 - val_mae: 0.7415\n",
      "Epoch 70/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0580 - val_loss: 1.1645 - val_mae: 0.7172\n",
      "Epoch 71/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0589 - val_loss: 1.1307 - val_mae: 0.7053\n",
      "Epoch 72/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0584 - val_loss: 1.0373 - val_mae: 0.6678\n",
      "Epoch 73/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0573 - val_loss: 1.1747 - val_mae: 0.7141\n",
      "Epoch 74/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0560 - val_loss: 1.0881 - val_mae: 0.6804\n",
      "Epoch 75/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0574 - val_loss: 1.1349 - val_mae: 0.7053\n",
      "Epoch 76/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0556 - val_loss: 1.1455 - val_mae: 0.6989\n",
      "Epoch 77/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0555 - val_loss: 1.0635 - val_mae: 0.6665\n",
      "Epoch 78/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0558 - val_loss: 1.1462 - val_mae: 0.7018\n",
      "Epoch 79/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0565 - val_loss: 1.1566 - val_mae: 0.7057\n",
      "Epoch 80/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0542 - val_loss: 1.0809 - val_mae: 0.6754\n",
      "Epoch 81/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0550 - val_loss: 1.1276 - val_mae: 0.6937\n",
      "Epoch 82/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0532 - val_loss: 1.1151 - val_mae: 0.6858\n",
      "Epoch 83/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0527 - val_loss: 1.1231 - val_mae: 0.6949\n",
      "Epoch 84/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0518 - val_loss: 1.0051 - val_mae: 0.6483\n",
      "Epoch 85/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0533 - val_loss: 1.0278 - val_mae: 0.6541\n",
      "Epoch 86/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0543 - val_loss: 1.0956 - val_mae: 0.6821\n",
      "Epoch 87/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0519 - val_loss: 1.0528 - val_mae: 0.6578\n",
      "Epoch 88/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0523 - val_loss: 1.2359 - val_mae: 0.7325\n",
      "Epoch 89/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0528 - val_loss: 0.9683 - val_mae: 0.6292\n",
      "Epoch 90/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0516 - val_loss: 1.0176 - val_mae: 0.6476\n",
      "Epoch 91/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0512 - val_loss: 1.1765 - val_mae: 0.7126\n",
      "Epoch 92/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0509 - val_loss: 1.0175 - val_mae: 0.6472\n",
      "Epoch 93/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0523 - val_loss: 1.0059 - val_mae: 0.6463\n",
      "Epoch 94/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0512 - val_loss: 1.1204 - val_mae: 0.6857\n",
      "Epoch 95/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0506 - val_loss: 1.0819 - val_mae: 0.6697\n",
      "Epoch 96/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0510 - val_loss: 1.0835 - val_mae: 0.6718\n",
      "Epoch 97/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0504 - val_loss: 1.0678 - val_mae: 0.6622\n",
      "Epoch 98/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0494 - val_loss: 1.1716 - val_mae: 0.7129\n",
      "Epoch 99/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0506 - val_loss: 1.1116 - val_mae: 0.6763\n",
      "Epoch 100/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0501 - val_loss: 1.0439 - val_mae: 0.6550\n",
      "Epoch 101/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0488 - val_loss: 1.0209 - val_mae: 0.6408\n",
      "Epoch 102/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0487 - val_loss: 1.0134 - val_mae: 0.6464\n",
      "Epoch 103/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0487 - val_loss: 1.0616 - val_mae: 0.6638\n",
      "Epoch 104/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0496 - val_loss: 1.1346 - val_mae: 0.6936\n",
      "Epoch 105/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0486 - val_loss: 1.1315 - val_mae: 0.6914\n",
      "Epoch 106/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0482 - val_loss: 1.1759 - val_mae: 0.7090\n",
      "Epoch 107/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0493 - val_loss: 1.0030 - val_mae: 0.6380\n",
      "Epoch 108/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0487 - val_loss: 1.1493 - val_mae: 0.6976\n",
      "Epoch 109/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0479 - val_loss: 1.1265 - val_mae: 0.6943\n",
      "Epoch 110/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0472 - val_loss: 1.1215 - val_mae: 0.6876\n",
      "Epoch 111/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0469 - val_loss: 1.0836 - val_mae: 0.6733\n",
      "Epoch 112/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0468 - val_loss: 1.1910 - val_mae: 0.7130\n",
      "Epoch 113/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0472 - val_loss: 1.1820 - val_mae: 0.7069\n",
      "Epoch 114/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0473 - val_loss: 1.1493 - val_mae: 0.6888\n",
      "Epoch 115/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0461 - val_loss: 1.1747 - val_mae: 0.7012\n",
      "Epoch 116/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0463 - val_loss: 1.1092 - val_mae: 0.6816\n",
      "Epoch 117/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0456 - val_loss: 1.2037 - val_mae: 0.7145\n",
      "Epoch 118/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0460 - val_loss: 1.1373 - val_mae: 0.6838\n",
      "Epoch 119/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0463 - val_loss: 1.1966 - val_mae: 0.7135\n",
      "Epoch 120/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0454 - val_loss: 1.0924 - val_mae: 0.6683\n",
      "Epoch 121/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0455 - val_loss: 1.0348 - val_mae: 0.6455\n",
      "Epoch 122/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0459 - val_loss: 1.2281 - val_mae: 0.7287\n",
      "Epoch 123/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0437 - val_loss: 1.1146 - val_mae: 0.6748\n",
      "Epoch 124/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0442 - val_loss: 1.0301 - val_mae: 0.6490\n",
      "Epoch 125/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0458 - val_loss: 1.0990 - val_mae: 0.6733\n",
      "Epoch 126/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0457 - val_loss: 1.1131 - val_mae: 0.6719\n",
      "Epoch 127/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0446 - val_loss: 1.0412 - val_mae: 0.6525\n",
      "Epoch 128/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0445 - val_loss: 1.0206 - val_mae: 0.6461\n",
      "Epoch 129/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0438 - val_loss: 1.0801 - val_mae: 0.6594\n",
      "Epoch 130/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0447 - val_loss: 1.1101 - val_mae: 0.6702\n",
      "Epoch 131/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0453 - val_loss: 1.1503 - val_mae: 0.6889\n",
      "Epoch 132/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0447 - val_loss: 1.0978 - val_mae: 0.6690\n",
      "Epoch 133/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0429 - val_loss: 1.1935 - val_mae: 0.7049\n",
      "Epoch 134/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0432 - val_loss: 1.0775 - val_mae: 0.6618\n",
      "Epoch 135/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0445 - val_loss: 1.1472 - val_mae: 0.6932\n",
      "Epoch 136/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0423 - val_loss: 1.0941 - val_mae: 0.6676\n",
      "Epoch 137/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0437 - val_loss: 1.1955 - val_mae: 0.7043\n",
      "Epoch 138/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0440 - val_loss: 1.0502 - val_mae: 0.6510\n",
      "Epoch 139/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0426 - val_loss: 1.0185 - val_mae: 0.6429\n",
      "Epoch 140/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0427 - val_loss: 1.0871 - val_mae: 0.6658\n",
      "Epoch 141/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0433 - val_loss: 1.0944 - val_mae: 0.6675\n",
      "Epoch 142/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0436 - val_loss: 1.0775 - val_mae: 0.6650\n",
      "Epoch 143/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0414 - val_loss: 1.0299 - val_mae: 0.6376\n",
      "Epoch 144/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0424 - val_loss: 1.0400 - val_mae: 0.6494\n",
      "Epoch 145/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0422 - val_loss: 1.1325 - val_mae: 0.6755\n",
      "Epoch 146/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0434 - val_loss: 1.0792 - val_mae: 0.6560\n",
      "Epoch 147/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0426 - val_loss: 1.1116 - val_mae: 0.6653\n",
      "Epoch 148/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0425 - val_loss: 1.1515 - val_mae: 0.6861\n",
      "Epoch 149/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0426 - val_loss: 1.0679 - val_mae: 0.6544\n",
      "Epoch 150/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0443 - val_loss: 0.9928 - val_mae: 0.6298\n",
      "Epoch 151/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0427 - val_loss: 1.1290 - val_mae: 0.6793\n",
      "Epoch 152/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0419 - val_loss: 1.1266 - val_mae: 0.6695\n",
      "Epoch 153/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0416 - val_loss: 1.1760 - val_mae: 0.6993\n",
      "Epoch 154/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0420 - val_loss: 1.0915 - val_mae: 0.6567\n",
      "Epoch 155/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0411 - val_loss: 1.1249 - val_mae: 0.6727\n",
      "Epoch 156/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0413 - val_loss: 1.1075 - val_mae: 0.6665\n",
      "Epoch 157/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0419 - val_loss: 1.1265 - val_mae: 0.6710\n",
      "Epoch 158/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0419 - val_loss: 1.0477 - val_mae: 0.6472\n",
      "Epoch 159/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0413 - val_loss: 1.0278 - val_mae: 0.6401\n",
      "Epoch 160/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0405 - val_loss: 1.1756 - val_mae: 0.6845\n",
      "Epoch 161/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0416 - val_loss: 1.0883 - val_mae: 0.6553\n",
      "Epoch 162/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0056 - mae: 0.0387 - val_loss: 1.1839 - val_mae: 0.6936\n",
      "Epoch 163/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0393 - val_loss: 1.1050 - val_mae: 0.6610\n",
      "Epoch 164/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0409 - val_loss: 1.1866 - val_mae: 0.7011\n",
      "Epoch 165/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0404 - val_loss: 1.1269 - val_mae: 0.6719\n",
      "Epoch 166/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0400 - val_loss: 1.1195 - val_mae: 0.6695\n",
      "Epoch 167/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0397 - val_loss: 1.1160 - val_mae: 0.6619\n",
      "Epoch 168/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0409 - val_loss: 1.1126 - val_mae: 0.6647\n",
      "Epoch 169/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0056 - mae: 0.0392 - val_loss: 1.1747 - val_mae: 0.6924\n",
      "Epoch 170/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0408 - val_loss: 1.0427 - val_mae: 0.6424\n",
      "Epoch 171/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0399 - val_loss: 1.1780 - val_mae: 0.6930\n",
      "Epoch 172/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0403 - val_loss: 1.1217 - val_mae: 0.6668\n",
      "Epoch 173/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0392 - val_loss: 1.1728 - val_mae: 0.6949\n",
      "Epoch 174/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0404 - val_loss: 1.1267 - val_mae: 0.6765\n",
      "Epoch 175/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0389 - val_loss: 1.0969 - val_mae: 0.6623\n",
      "Epoch 176/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0388 - val_loss: 1.2367 - val_mae: 0.7198\n",
      "Epoch 177/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0393 - val_loss: 1.1663 - val_mae: 0.6831\n",
      "Epoch 178/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0396 - val_loss: 1.1990 - val_mae: 0.7025\n",
      "Epoch 179/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0386 - val_loss: 1.1442 - val_mae: 0.6819\n",
      "Epoch 180/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0386 - val_loss: 1.3271 - val_mae: 0.7495\n",
      "Epoch 181/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0386 - val_loss: 1.1195 - val_mae: 0.6687\n",
      "Epoch 182/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0389 - val_loss: 1.1133 - val_mae: 0.6644\n",
      "Epoch 183/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0389 - val_loss: 1.1467 - val_mae: 0.6790\n",
      "Epoch 184/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0388 - val_loss: 1.1667 - val_mae: 0.6916\n",
      "Epoch 185/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0389 - val_loss: 1.1141 - val_mae: 0.6634\n",
      "Epoch 186/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0389 - val_loss: 1.2471 - val_mae: 0.7342\n",
      "Epoch 187/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0389 - val_loss: 1.1665 - val_mae: 0.6824\n",
      "Epoch 188/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0397 - val_loss: 1.1929 - val_mae: 0.6951\n",
      "Epoch 189/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0394 - val_loss: 1.1982 - val_mae: 0.6925\n",
      "Epoch 190/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0368 - val_loss: 1.1164 - val_mae: 0.6650\n",
      "Epoch 191/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0395 - val_loss: 1.2090 - val_mae: 0.6972\n",
      "Epoch 192/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0386 - val_loss: 1.2750 - val_mae: 0.7283\n",
      "Epoch 193/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0387 - val_loss: 1.1482 - val_mae: 0.6806\n",
      "Epoch 194/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0368 - val_loss: 1.1649 - val_mae: 0.6804\n",
      "Epoch 195/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0385 - val_loss: 1.2549 - val_mae: 0.7165\n",
      "Epoch 196/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0362 - val_loss: 1.1438 - val_mae: 0.6735\n",
      "Epoch 197/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0383 - val_loss: 1.1782 - val_mae: 0.6892\n",
      "Epoch 198/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0385 - val_loss: 1.1943 - val_mae: 0.6946\n",
      "Epoch 199/200\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0376 - val_loss: 1.1825 - val_mae: 0.6841\n",
      "Epoch 200/200\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0381 - val_loss: 1.1584 - val_mae: 0.6802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a6a4efb50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLES = Y.__len__()  \n",
    "\n",
    "x_values = X.to_numpy()\n",
    "\n",
    "Y = Y.replace(\"A\", 0)\n",
    "Y = Y.replace(\"E\", 1)\n",
    "Y = Y.replace(\"I\", 2)\n",
    "Y = Y.replace(\"O\", 3)\n",
    "Y = Y.replace(\"U\", 4)\n",
    " \n",
    "y_values = Y.to_numpy()\n",
    "\n",
    "# divide dados em treinamento, validação e teste\n",
    "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
    "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
    "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "# cria uma rede neural de 2 camadas de 16 neurônicos cada\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(180,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(5)) #, activation=\"softmax\"))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=16, validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, verbose=False):\n",
    "    y_test = random_state=1\n",
    "    y_pred= model.predict(x_test)\n",
    "    print('MAE', np.abs(y_pred - y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(3, 6), max_iter=5000,\n",
       "              random_state=1, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(3, 6), max_iter=5000,\n",
       "              random_state=1, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(3, 6), max_iter=5000,\n",
       "              random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import random\n",
    "#seed = random.randrange(3847)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3,6), random_state=1, max_iter=5000, activation='relu') #2 camadas ocultas com 2 neurônios\n",
    "clf.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.title('Classifier neural network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.75      0.51       216\n",
      "           1       0.95      0.94      0.94       240\n",
      "           2       0.59      0.93      0.72       222\n",
      "           3       0.35      0.57      0.43       260\n",
      "           4       0.00      0.00      0.00       519\n",
      "\n",
      "    accuracy                           0.51      1457\n",
      "   macro avg       0.46      0.64      0.52      1457\n",
      "weighted avg       0.37      0.51      0.42      1457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model \n",
    "#### Converter model to \"tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step\n",
      "MAE 1.3803707\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\CLAUDI~1\\AppData\\Local\\Temp\\tmpkyej8jnu\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\CLAUDI~1\\AppData\\Local\\Temp\\tmpkyej8jnu\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20460"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, verbose=True)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model) \n",
    "tflite_model = converter.convert() \n",
    "# Save the model to disk \n",
    "open(\"morse_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert model to an array in 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i sine_model.tflite > morse_model.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "848288dc05b0f1c4a018431f6431236dd3c4f2b73933b42ab2a9ae7f8c2bf161"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Prepare dataframes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Renan's dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renan = pd.DataFrame()\n",
    "\n",
    "# for each file in directory, create a new dataframe\n",
    "folder = \"..\\\\letters\\\\Renan\"\n",
    "for directory, subfolder, files in os.walk(folder):     \n",
    "     for file in files:\n",
    "          targetLetter = file.replace(\".csv\",\"\")\n",
    "          # Create a dataframe without header and drop last column\n",
    "          df = pd.DataFrame()\n",
    "          df = pd.read_csv(os.path.join(os.path.realpath(directory), file), header=None, sep=\";\")\n",
    "          df = df.drop(180, axis=1)\n",
    "          df[\"Target letter\"] = targetLetter\n",
    "          df[\"Target person\"] = \"Renan\"\n",
    "\n",
    "          renan = pd.concat([renan,df])\n",
    "          \n",
    "renan = renan.reset_index(drop=True)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Claudinei's dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claudinei = pd.DataFrame()\n",
    "\n",
    "# for each file in directory, create a new dataframe\n",
    "folder = \"..\\\\letters\\\\Claudinei\"\n",
    "for directory, subfolder, files in os.walk(folder):     \n",
    "     for file in files:\n",
    "          targetLetter = file.replace(\".csv\",\"\")\n",
    "          # Create a dataframe without header and drop last column\n",
    "          df = pd.DataFrame()\n",
    "          df = pd.read_csv(os.path.join(os.path.realpath(directory), file), header=None, sep=\";\")\n",
    "          df = df.drop(180, axis=1)\n",
    "          df[\"Target letter\"] = targetLetter\n",
    "          df[\"Target person\"] = \"Claudinei\"\n",
    "\n",
    "          claudinei = pd.concat([claudinei,df])\n",
    "          \n",
    "claudinei = claudinei.reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Guilherme's dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guilherme = pd.DataFrame()\n",
    "\n",
    "# for each file in directory, create a new dataframe\n",
    "folder = \"..\\\\letters\\\\Guilherme\"\n",
    "for directory, subfolder, files in os.walk(folder):     \n",
    "     for file in files:\n",
    "          targetLetter = file.replace(\".csv\",\"\")\n",
    "          # Create a dataframe without header and drop last column\n",
    "          df = pd.DataFrame()\n",
    "          df = pd.read_csv(os.path.join(os.path.realpath(directory), file), header=None, sep=\";\")\n",
    "          df = df.drop(180, axis=1)\n",
    "          df[\"Target letter\"] = targetLetter\n",
    "          df[\"Target person\"] = \"Guilherme\"\n",
    "\n",
    "          guilherme = pd.concat([guilherme,df])\n",
    "          \n",
    "guilherme = guilherme.reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupDataframe = pd.concat([renan,claudinei,guilherme])\n",
    "groupDataframe = groupDataframe.reset_index(drop=True)\n",
    "groupDataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Training</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Neural network</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = groupDataframe.iloc[:,0:180]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = groupDataframe.iloc[:,180]\n",
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = groupDataframe.iloc[:,181]\n",
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y1, test_size=0.3, random_state=4845)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, Y2, test_size=0.3, random_state=478)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(4,3), random_state=1, max_iter=5000, activation='relu') #2 camadas ocultas com 2 neurônios\n",
    "clf1.fit(X1_train, np.ravel(y1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = random.randrange(1268) \n",
    "clf2 = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(150,120), random_state=seed, max_iter=5000, activation='logistic') #2 camadas ocultas com 2 neurônios\n",
    "clf2.fit(X2_train, np.ravel(y2_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = clf1.predict(X1_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y1_test, y1_pred)\n",
    "plt.title('Classifier neural network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = clf2.predict(X2_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y2_test, y2_pred)\n",
    "plt.title('Classifier neural network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Instant translate</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.1 Bayes classifier</h3/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the probability of each letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probA = groupDataframe[(groupDataframe[\"targetLetter\"] == 'A')]#.value_counts()/len(groupDataframe.index)\n",
    "probA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupDataframe[\"A\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a84d6694d99063d2bb0286ebc4a83b7a5fbbe8812bdd85c9b7227af9c494503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
